{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing empty lists\n",
    "category, price, desc, rating, num_rating, discount, mrp, is_fassured, timestamp = [], [], [], [], [], [], [], [], []\n",
    "\n",
    "#URLs\n",
    "add = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken : 137.30257391929626 sec\n"
     ]
    }
   ],
   "source": [
    "# Script to scrap wearable smart devices by popularity\n",
    "start = time.time()\n",
    "\n",
    "url = \"https://www.flipkart.com/computers/desktop-pcs/pr?sid=6bo,nl4&p[]=facets.serviceability%5B%5D%3Dtrue&otracker=categorytree\"\n",
    "driver = webdriver.Chrome()\n",
    "dcap = dict(DesiredCapabilities.CHROME)\n",
    "dcap[\"chrome.page.settings.userAgent\"] = (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.18362\")\n",
    "driver = webdriver.Chrome(desired_capabilities = dcap, service_args = ['--ignore-ssl-errors=true'])\n",
    "driver.implicitly_wait(20)\n",
    "driver.get(url)\n",
    "\n",
    "# Fetching 14 pages from Desktop_PCs category\n",
    "for i in range(1,14):\n",
    "    \n",
    "    driver.get(url)\n",
    "\n",
    "    content = driver.page_source\n",
    "\n",
    "    with open('../Desktop_PCs/Desktop_PCs_Data/Desktop_PCs_' + str(i) + '.txt', 'w', encoding = 'utf-8') as f:\n",
    "        f.write(content)\n",
    "        f.close()\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    for div in soup.find_all('div', attrs = {'class' : '_3liAhj _1R0K0g'}):\n",
    "        pr = div.find('div', attrs = {'class' : '_1vC4OE'})\n",
    "        des = div.find('a', attrs = {'class' : '_2cLu-l'})\n",
    "        rt = div.find('div', attrs = {'class' : 'hGSR34'})\n",
    "        no_rt = div.find('span', attrs = {'class', '_38sUEc'})\n",
    "        dis = div.find('div', attrs = {'class' : 'VGWI6T'})\n",
    "        mr = div.find('div', attrs = {'class' : '_3auQ3N'})\n",
    "        fassured = div.find('div', attrs = {'class' : '_3LWrw9'})\n",
    "        \n",
    "        if pr == None:\n",
    "            price.append(0)\n",
    "        else:\n",
    "            price.append(pr.text)\n",
    "    \n",
    "        if des == None:\n",
    "            desc.append(0)\n",
    "        else:\n",
    "            desc.append(des['title'])\n",
    "        \n",
    "        if rt == None:\n",
    "            rating.append(0)\n",
    "        else:\n",
    "            rating.append(rt.text)\n",
    "        \n",
    "        if no_rt == None:\n",
    "            num_rating.append(0)\n",
    "        else:\n",
    "            num_rating.append(no_rt.text)\n",
    "        \n",
    "        if dis == None:\n",
    "            discount.append(0)\n",
    "        else:\n",
    "            discount.append(dis.text)\n",
    "        \n",
    "        if mr == None:\n",
    "            mrp.append(0)\n",
    "        else:\n",
    "            mrp.append(mr.text)\n",
    "            \n",
    "        if fassured == None:\n",
    "            is_fassured.append(0)\n",
    "        else:\n",
    "            is_fassured.append(1)\n",
    "        \n",
    "        timestamp.append(datetime.datetime.now())\n",
    "    \n",
    "    # Using click() to navigate through desktop pcs pages\n",
    "\n",
    "    add.append(url)\n",
    "    next_link = driver.find_element_by_link_text(str(i+1))\n",
    "    next_link.click()\n",
    "    \n",
    "    time.sleep(7)\n",
    "    \n",
    "    driver.implicitly_wait(20)\n",
    "    url = driver.current_url\n",
    "    \n",
    "print('Time Taken : {} sec'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktops = pd.DataFrame({\n",
    "    'category' : np.repeat('Desktop PCs', len(price)),\n",
    "    'price' : price,\n",
    "    'description' : desc,\n",
    "    'rating' : rating,\n",
    "    'num_ratings' : num_rating,\n",
    "    'discount' : discount,\n",
    "    'mrp' : mrp,\n",
    "    'is_fassured' : is_fassured,\n",
    "    'timestamp' : timestamp\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktops.to_csv('../Desktop_PCs/Desktop_PCs_CSVs/Desktop_PCs.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
