{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing empty lists\n",
    "category, price, desc, rating, num_rating, discount, mrp, warranty, is_fassured, timestamp = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "# URLs\n",
    "add = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken : 289.77275681495667 sec\n"
     ]
    }
   ],
   "source": [
    "# Script to scrap tablets by popularity\n",
    "start = time.time()\n",
    "\n",
    "url = \"https://www.flipkart.com/tablets/pr?sid=hry&p[]=facets.serviceability%5B%5D%3Dtrue&otracker=categorytree\"\n",
    "driver = webdriver.Chrome()\n",
    "dcap = dict(DesiredCapabilities.CHROME)\n",
    "dcap[\"chrome.page.settings.userAgent\"] = (\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.102 Safari/537.36 Edge/18.18362\")\n",
    "driver = webdriver.Chrome(desired_capabilities = dcap, service_args = ['--ignore-ssl-errors=true'])\n",
    "driver.implicitly_wait(20)\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "# Scraping 30 tablets pages\n",
    "for i in range(1,30):\n",
    "    \n",
    "    driver.get(url)\n",
    "\n",
    "    content = driver.page_source\n",
    "\n",
    "    with open('../Tablets/Tablets_Data/Tablets_' + str(i) + '.txt', 'w', encoding = 'utf-8') as f:\n",
    "        f.write(content)\n",
    "        f.close()\n",
    "    \n",
    "    soup = BeautifulSoup(content)\n",
    "\n",
    "    for a in soup.find_all('a', href = True, attrs = {'class' : '_31qSD5'}):\n",
    "        pr = a.find('div', attrs = {'class' : '_1vC4OE _2rQ-NK'})\n",
    "        des = a.find('div', attrs = {'class' : '_3wU53n'})\n",
    "        rt = a.find('div', attrs = {'class' : 'hGSR34'})\n",
    "        no_rt = a.find('span', attrs = {'class', '_38sUEc'})\n",
    "        dis = a.find('div', attrs = {'class' : 'VGWI6T'})\n",
    "        mr = a.find('div', attrs = {'class' : '_3auQ3N _2GcJzG'})\n",
    "        wrnty = a.find('ul', attrs = {'class' : 'vFw0gD'})\n",
    "        fassured = a.find('div', attrs = {'class' : '_3n6o0t'})\n",
    "    \n",
    "        if pr == None:\n",
    "            price.append(0)\n",
    "        else:\n",
    "            price.append(pr.text)\n",
    "    \n",
    "        if des == None:\n",
    "            desc.append(0)\n",
    "        else:\n",
    "            desc.append(des.text)\n",
    "        \n",
    "        if rt == None:\n",
    "            rating.append(0)\n",
    "        else:\n",
    "            rating.append(rt.text)\n",
    "        \n",
    "        if no_rt == None:\n",
    "            num_rating.append(0)\n",
    "        else:\n",
    "            num_rating.append(no_rt.text)\n",
    "        \n",
    "        if dis == None:\n",
    "            discount.append(0)\n",
    "        else:\n",
    "            discount.append(dis.text)\n",
    "        \n",
    "        if mr == None:\n",
    "            mrp.append(0)\n",
    "        else:\n",
    "            mrp.append(mr.text)\n",
    "        \n",
    "        if wrnty == None:\n",
    "            warranty.append(0)\n",
    "        else:\n",
    "            warranty.append(wrnty.text)\n",
    "            \n",
    "        if fassured == None:\n",
    "            is_fassured.append(0)\n",
    "        else:\n",
    "            is_fassured.append(1)\n",
    "        \n",
    "        timestamp.append(datetime.datetime.now())\n",
    "    \n",
    "    # Using click() to navigate through tablets pages\n",
    "\n",
    "    add.append(url)\n",
    "    next_link = driver.find_elements_by_class_name('_3fVaIS')\n",
    "    next_link[-1].click()\n",
    "    \n",
    "    time.sleep(7)\n",
    "    \n",
    "    driver.implicitly_wait(20)\n",
    "    url = driver.current_url\n",
    "    \n",
    "print('Time Taken : {} sec'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablets = pd.DataFrame({\n",
    "    'category' : np.repeat('Tablet', len(price)),\n",
    "    'price' : price,\n",
    "    'description' : desc,\n",
    "    'rating' : rating,\n",
    "    'num_ratings_reviews' : num_rating,\n",
    "    'discount' : discount,\n",
    "    'mrp' : mrp,\n",
    "    'details' : warranty,\n",
    "    'is_fassured' : is_fassured,\n",
    "    'timestamp' : timestamp\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablets.to_csv('../Tablets/Tablets_CSVs/Tablets.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
